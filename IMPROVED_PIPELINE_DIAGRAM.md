# Improved Knowledge Distillation Pipeline Diagram

## Complete Pipeline Flow (2 Cycles, 3 Questions Each)

```mermaid
flowchart TD
    A[ðŸš€ User Clicks Start Pipeline] --> B[ðŸ“‹ Load Configuration]
    B --> C[ðŸ“š Load Kubernetes v1.28 Knowledge Base]
    C --> D[ðŸŽ¯ Select Topics: Pods, Services, Storage]
    
    D --> E[ðŸ”„ CYCLE 1 START]
    E --> F[â“ Generate 3 Questions using GPT-4o-mini]
    F --> G[ðŸ’¾ Save Questions Checkpoint]
    
    G --> H[ðŸ¤– Load Phi-2 Model 4-bit QLoRA]
    H --> I[â“ Generate Baseline Answers for 3 Questions]
    I --> J[ðŸ’¾ Save Baseline Answers]
    
    J --> K[ðŸ‘¨â€ðŸ« Generate Reference Answers using GPT-4o-mini]
    K --> L[ðŸ’¾ Save Reference Answers]
    
    L --> M[ðŸ“Š Evaluate Baseline Answers using RAGAS]
    M --> N[ðŸ“ˆ Calculate Baseline Relevancy Score]
    N --> O[ðŸ’¾ Save Baseline Evaluation]
    
    O --> P[âš™ï¸ Prepare Training Dataset 3 Q&A Pairs]
    P --> Q[ðŸ§  Fine-tune Phi-2 with QLoRA]
    Q --> R[ðŸ’¾ Save Fine-tuned Adapter]
    R --> S[âœ… Fine-tuning Complete]
    
    S --> T[ðŸ¤– Load Fine-tuned Phi-2 Model]
    T --> U[â“ Generate Fine-tuned Answers for 3 Questions]
    U --> V[ðŸ’¾ Save Fine-tuned Answers]
    
    V --> W[ðŸ“Š Evaluate Fine-tuned Answers using RAGAS]
    W --> X[ðŸ“ˆ Calculate Fine-tuned Relevancy Score]
    X --> Y[ðŸ’¾ Save Fine-tuned Evaluation]
    
    Y --> Z[ðŸ“Š Compare Baseline vs Fine-tuned Performance]
    Z --> AA[ðŸ“ˆ Calculate Improvement Metrics]
    AA --> BB[ðŸ’¾ Save Cycle 1 Complete Results]
    
    BB --> CC[ðŸ”„ CYCLE 2 START]
    CC --> DD[â“ Generate 3 NEW Questions using GPT-4o-mini]
    DD --> EE[ðŸ’¾ Save Cycle 2 Questions]
    
    EE --> FF[ðŸ¤– Load Fine-tuned Phi-2 from Cycle 1]
    FF --> GG[â“ Generate Baseline Answers for 3 NEW Questions]
    GG --> HH[ðŸ’¾ Save Cycle 2 Baseline Answers]
    
    HH --> II[ðŸ‘¨â€ðŸ« Generate Reference Answers for NEW Questions]
    II --> JJ[ðŸ’¾ Save Cycle 2 Reference Answers]
    
    JJ --> KK[ðŸ“Š Evaluate Cycle 2 Baseline Answers]
    KK --> LL[ðŸ“ˆ Calculate Cycle 2 Baseline Score]
    LL --> MM[ðŸ’¾ Save Cycle 2 Baseline Evaluation]
    
    MM --> NN[âš™ï¸ Prepare Training Dataset 6 Q&A Pairs Total]
    NN --> OO[ðŸ§  Fine-tune Phi-2 with QLoRA Round 2]
    OO --> PP[ðŸ’¾ Save Cycle 2 Fine-tuned Adapter]
    PP --> QQ[âœ… Cycle 2 Fine-tuning Complete]
    
    QQ --> RR[ðŸ¤– Load Cycle 2 Fine-tuned Phi-2]
    RR --> SS[â“ Generate Cycle 2 Fine-tuned Answers]
    SS --> TT[ðŸ’¾ Save Cycle 2 Fine-tuned Answers]
    
    TT --> UU[ðŸ“Š Evaluate Cycle 2 Fine-tuned Answers]
    UU --> VV[ðŸ“ˆ Calculate Cycle 2 Fine-tuned Score]
    VV --> WW[ðŸ’¾ Save Cycle 2 Fine-tuned Evaluation]
    
    WW --> XX[ðŸ“Š Compare All Cycles Performance]
    XX --> YY[ðŸ“ˆ Calculate Overall Improvement]
    YY --> ZZ[ðŸ’¾ Save Complete Pipeline Results]
    
    ZZ --> AAA[ðŸ PIPELINE COMPLETE]
    AAA --> BBB[ðŸ“Š Display Final Results]
    BBB --> CCC[ðŸ“ˆ Show Performance Comparison]
    CCC --> DDD[ðŸŽ¯ Display Improvement Statistics]
    DDD --> EEE[ðŸ“‹ Show Sample Q&A Pairs from Both Cycles]
    
    %% Styling
    classDef startEnd fill:#e1f5fe,stroke:#01579b,stroke-width:3px
    classDef cycle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef process fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef save fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef model fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef evaluation fill:#e0f2f1,stroke:#004d40,stroke-width:2px
    classDef training fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    
    class A,AAA startEnd
    class E,CC cycle
    class B,C,D,F,H,I,K,M,N,P,Q,S,T,U,W,X,Z,AA,DD,FF,GG,II,KK,LL,NN,OO,QQ,RR,SS,UU,VV,XX,YY,BBB,CCC,DDD,EEE process
    class G,J,L,O,R,V,Y,BB,EE,HH,JJ,LL,PP,TT,VV,ZZ save
    class H,FF model
    class M,N,W,X,KK,LL,UU,VV evaluation
    class Q,OO training
```

## Detailed Metrics Flow

```mermaid
flowchart TD
    A[ðŸ“Š Start Pipeline Evaluation] --> B[ðŸ“ˆ Cycle 1 Baseline Score]
    B --> C[ðŸ“ˆ Cycle 1 Fine-tuned Score]
    
    C --> D[ðŸ“Š Cycle 1 Improvement]
    D --> E[ðŸ“ˆ Cycle 2 Baseline Score]
    E --> F[ðŸ“ˆ Cycle 2 Fine-tuned Score]
    
    F --> G[ðŸ“Š Cycle 2 Improvement]
    G --> H[ðŸ“ˆ Overall Performance Analysis]
    
    H --> I[ðŸ“‹ Generate Comprehensive Report]
    I --> J[ðŸ“Š Display Final Results]
    
    J --> K[ðŸ“ˆ Answer Relevancy Scores]
    J --> L[ðŸ“ˆ Improvement Percentages]
    J --> M[ðŸ“ˆ Success Rates]
    J --> N[ðŸ“ˆ Training Times]
    J --> O[ðŸ“ˆ Model Convergence]
    
    K --> P[ðŸ’¾ Save Final Report]
    L --> P
    M --> P
    N --> P
    O --> P
    
    P --> Q[ðŸŽ¯ Pipeline Complete]
    
    %% Styling
    classDef metric fill:#e3f2fd,stroke:#0277bd,stroke-width:2px
    classDef process fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef cycle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    
    class K,L,M,N,O metric
    class A,B,C,D,E,F,G,H,I,J,P,Q process
    class B,C,D,E,F,G cycle
```

## Data Flow Between Cycles

```mermaid
flowchart LR
    A[Kubernetes Knowledge Base] --> B[GPT-4o-mini Teacher]
    B --> C[Cycle 1: 3 Questions + References]
    C --> D[Phi-2 Student Baseline]
    C --> E[Training Dataset 1]
    E --> F[QLoRA Fine-tuning Round 1]
    F --> G[Fine-tuned Phi-2 Round 1]
    
    G --> H[Cycle 2: 3 NEW Questions + References]
    H --> I[Phi-2 Student Baseline Round 2]
    H --> J[Training Dataset 2: 6 Total Pairs]
    J --> K[QLoRA Fine-tuning Round 2]
    K --> L[Fine-tuned Phi-2 Round 2]
    
    D --> M[RAGAS Evaluation]
    G --> M
    I --> M
    L --> M
    
    M --> N[Performance Comparison]
    N --> O[Final Results]
    
    classDef data fill:#e0f2f1,stroke:#004d40,stroke-width:2px
    classDef model fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef process fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef cycle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef output fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    
    class A,C,H data
    class B,D,G,I,L model
    class F,K,M,N process
    class C,H cycle
    class O output
```

## Memory Management Across Cycles

```mermaid
flowchart TD
    A[ðŸ”„ Start Pipeline] --> B{ðŸ’¾ Check GPU Memory}
    B -->|>4GB| C[ðŸš€ Use GPU Mode]
    B -->|<4GB| D[ðŸ’» Use CPU Mode]
    
    C --> E[ðŸ¤– Load Phi-2 4-bit QLoRA]
    D --> F[ðŸ¤– Load Phi-2 on CPU]
    
    E --> G[ðŸ§  Generate Cycle 1 Answers]
    F --> G
    
    G --> H[ðŸ§¹ Clear GPU Memory]
    H --> I[ðŸ’¾ Save Cycle 1 Results]
    
    I --> J[ðŸ”„ Cycle 2: Load Fine-tuned Model]
    J --> K{ðŸ’¾ Check GPU Memory}
    K -->|>4GB| L[ðŸš€ Use GPU Mode]
    K -->|<4GB| M[ðŸ’» Use CPU Mode]
    
    L --> N[ðŸ¤– Load Fine-tuned Phi-2]
    M --> N
    
    N --> O[ðŸ§  Generate Cycle 2 Answers]
    O --> P[ðŸ§¹ Clear GPU Memory]
    P --> Q[ðŸ’¾ Save Cycle 2 Results]
    
    Q --> R[ðŸ“Š Final Evaluation]
    R --> S[âœ… Pipeline Complete]
    
    classDef decision fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef process fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef memory fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef cycle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    
    class B,K decision
    class A,C,D,E,F,G,J,L,M,N,O,R,S process
    class H,P memory
    class G,O cycle
```

## Key Features of This Improved Diagram:

1. **Shows 2 complete cycles** with 3 questions each
2. **Demonstrates model improvement** between cycles
3. **Includes memory management** across cycles
4. **Shows data accumulation** (6 total Q&A pairs by end)
5. **Displays comprehensive metrics** for both cycles
6. **Color-coded phases** for easy understanding
7. **Includes all checkpoints** and save points

This diagram provides a complete visual representation of how the knowledge distillation pipeline works across multiple cycles! ðŸŽ¯ 